#!/usr/bin/env python3
"""
Algorithme de s√©lection automatique du meilleur filtre de d√©sentrelacement
bas√© sur l'analyse du mouvement et des caract√©ristiques de la vid√©o.
"""

import subprocess
import json
import re
import numpy as np
from pathlib import Path
from typing import Dict, Tuple, Optional
from dataclasses import dataclass
from enum import Enum


class DeinterlaceFilter(Enum):
    """Filtres de d√©sentrelacement disponibles"""
    YADIF = "yadif"
    BWDIF = "bwdif"
    ESTDIF = "estdif"
    W3FDIF = "w3fdif"
    NNEDI = "nnedi" 


@dataclass
class VideoAnalysis:
    """R√©sultats de l'analyse vid√©o"""
    avg_motion: float
    max_motion: float
    motion_variance: float
    scene_changes: int
    complexity: float
    interlaced_frames: float
    has_film_content: bool
    temporal_consistency: float


@dataclass
class FilterRecommendation:
    """Recommandation de filtre avec justification"""
    filter: DeinterlaceFilter
    mode: int
    confidence: float
    reason: str
    alternative: Optional[DeinterlaceFilter] = None


class DeinterlaceSelector:
    """
    S√©lecteur intelligent de filtre de d√©sentrelacement
    bas√© sur l'analyse du contenu vid√©o
    """
    
    # Seuils de d√©cision
    THRESHOLDS = {
        'high_motion': 0.15,      # Motion √©lev√©
        'low_motion': 0.05,        # Motion faible
        'high_complexity': 0.3,    # Complexit√© spatiale √©lev√©e
        'scene_change_rate': 0.05, # Taux de changement de sc√®ne
        'film_confidence': 0.7,    # Confiance d√©tection film
    }
    
    def __init__(self, video_path: str, sample_duration: int = 30):
        """
        Args:
            video_path: Chemin vers la vid√©o √† analyser
            sample_duration: Dur√©e d'√©chantillon pour l'analyse (secondes)
        """
        self.video_path = Path(video_path)
        self.sample_duration = sample_duration
        self.analysis: Optional[VideoAnalysis] = None
    
    def analyze_video(self) -> VideoAnalysis:
        """
        Premi√®re passe: analyse du mouvement et des caract√©ristiques
        """
        print(f"üîç Analyse de la vid√©o: {self.video_path.name}")
        
        # 1. Analyse du mouvement avec freezedetect et idet
        motion_data = self._analyze_motion()
        
        # 2. D√©tection d'entrelacement
        interlace_data = self._detect_interlacing()
        
        # 3. Analyse de complexit√© spatiale
        complexity = self._analyze_complexity()
        
        # 4. D√©tection de contenu film (telecine)
        film_detection = self._detect_film_content()
        
        # 5. Analyse de coh√©rence temporelle
        temporal = self._analyze_temporal_consistency()
        
        self.analysis = VideoAnalysis(
            avg_motion=motion_data['avg'],
            max_motion=motion_data['max'],
            motion_variance=motion_data['variance'],
            scene_changes=motion_data['scene_changes'],
            complexity=complexity,
            interlaced_frames=interlace_data['interlaced_ratio'],
            has_film_content=film_detection,
            temporal_consistency=temporal
        )
        
        return self.analysis
    
    def _analyze_motion(self) -> Dict[str, float]:
        """Analyse le mouvement avec le filtre mestimate"""
        cmd = [
            'ffmpeg',
            '-i', str(self.video_path),
            '-t', str(self.sample_duration),
            '-vf', 'mestimate=method=esa,metadata=print:file=-',
            '-f', 'null',
            '-'
        ]
        
        try:
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                check=True
            )
            
            # Parser les m√©tadonn√©es de mouvement
            motion_values = []
            scene_changes = 0
            
            for line in result.stderr.split('\n'):
                # Rechercher les valeurs de mouvement
                if 'lavfi.mestimate.mb_sad' in line:
                    match = re.search(r'lavfi\.mestimate\.mb_sad=(\d+)', line)
                    if match:
                        motion_values.append(int(match.group(1)))
                
                # D√©tecter les changements de sc√®ne
                if 'lavfi.scene' in line or motion_values and motion_values[-1] > 50000:
                    scene_changes += 1
            
            if not motion_values:
                # Fallback: utiliser select et setpts
                return self._analyze_motion_fallback()
            
            motion_array = np.array(motion_values)
            
            return {
                'avg': np.mean(motion_array) / 10000.0,  # Normaliser
                'max': np.max(motion_array) / 10000.0,
                'variance': np.var(motion_array) / 100000000.0,
                'scene_changes': scene_changes
            }
            
        except subprocess.CalledProcessError:
            return self._analyze_motion_fallback()
    
    def _analyze_motion_fallback(self) -> Dict[str, float]:
        """M√©thode alternative d'analyse du mouvement"""
        # Utiliser mpdecimate pour estimer le mouvement
        cmd = [
            'ffmpeg',
            '-i', str(self.video_path),
            '-t', str(self.sample_duration),
            '-vf', 'mpdecimate,metadata=print:file=-',
            '-f', 'null',
            '-'
        ]
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            
            # Compter les frames dupliqu√©es (peu de mouvement)
            dropped = result.stderr.count('drop')
            total_frames = self.sample_duration * 25  # Assumer 25fps
            
            motion_estimate = 1.0 - (dropped / max(total_frames, 1))
            
            return {
                'avg': motion_estimate * 0.2,
                'max': motion_estimate * 0.4,
                'variance': 0.05,
                'scene_changes': max(1, int(total_frames / 100))
            }
        except:
            # Valeurs par d√©faut conservatrices
            return {
                'avg': 0.1,
                'max': 0.2,
                'variance': 0.05,
                'scene_changes': 5
            }
    
    def _detect_interlacing(self) -> Dict[str, float]:
        """D√©tecte le taux d'entrelacement avec idet"""
        cmd = [
            'ffmpeg',
            '-i', str(self.video_path),
            '-t', str(self.sample_duration),
            '-vf', 'idet',
            '-f', 'null',
            '-'
        ]
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            
            # Parser les r√©sultats idet
            tff = bff = progressive = 0
            
            for line in result.stderr.split('\n'):
                if 'Multi frame detection' in line:
                    match_tff = re.search(r'TFF:\s*(\d+)', line)
                    match_bff = re.search(r'BFF:\s*(\d+)', line)
                    match_prog = re.search(r'Progressive:\s*(\d+)', line)
                    
                    if match_tff:
                        tff = int(match_tff.group(1))
                    if match_bff:
                        bff = int(match_bff.group(1))
                    if match_prog:
                        progressive = int(match_prog.group(1))
            
            total = tff + bff + progressive
            if total == 0:
                return {'interlaced_ratio': 0.5}  # Inconnu, assumer entrelac√©
            
            interlaced_ratio = (tff + bff) / total
            
            return {
                'interlaced_ratio': interlaced_ratio,
                'tff': tff,
                'bff': bff,
                'progressive': progressive
            }
            
        except subprocess.CalledProcessError:
            return {'interlaced_ratio': 0.5}
    
    def _analyze_complexity(self) -> float:
        """Analyse la complexit√© spatiale de l'image"""
        cmd = [
            'ffmpeg',
            '-i', str(self.video_path),
            '-t', str(self.sample_duration),
            '-vf', 'select=not(mod(n\\,25)),signalstats',
            '-f', 'null',
            '-'
        ]
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            
            # Extraire les valeurs de complexit√© (YMIN, YMAX, etc.)
            complexity_values = []
            
            for line in result.stderr.split('\n'):
                if 'lavfi.signalstats.YDIF' in line:
                    match = re.search(r'lavfi\.signalstats\.YDIF=(\d+\.?\d*)', line)
                    if match:
                        complexity_values.append(float(match.group(1)))
            
            if complexity_values:
                return np.mean(complexity_values) / 100.0
            else:
                return 0.15  # Valeur moyenne par d√©faut
                
        except subprocess.CalledProcessError:
            return 0.15
    
    def _detect_film_content(self) -> bool:
        """D√©tecte si le contenu est du film (24fps) t√©l√©cin√© en 50i"""
        cmd = [
            'ffmpeg',
            '-i', str(self.video_path),
            '-t', str(self.sample_duration),
            '-vf', 'pullup,idet',
            '-f', 'null',
            '-'
        ]
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            
            # Chercher des patterns de telecine (3:2 pulldown adapt√© au PAL)
            repeated_frames = 0
            
            for line in result.stderr.split('\n'):
                if 'repeated' in line.lower():
                    repeated_frames += 1
            
            # Si plus de 20% de frames r√©p√©t√©es, c'est probablement du film
            total_frames = self.sample_duration * 25
            return (repeated_frames / max(total_frames, 1)) > 0.2
            
        except subprocess.CalledProcessError:
            return False
    
    def _analyze_temporal_consistency(self) -> float:
        """Analyse la coh√©rence temporelle entre frames"""
        cmd = [
            'ffmpeg',
            '-i', str(self.video_path),
            '-t', str(self.sample_duration),
            '-vf', 'tblend=all_mode=difference,metadata=print:file=-',
            '-f', 'null',
            '-'
        ]
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            
            # Mesurer la diff√©rence entre frames cons√©cutives
            differences = []
            
            for line in result.stderr.split('\n'):
                if 'lavfi.tblend' in line:
                    match = re.search(r'(\d+\.?\d*)', line)
                    if match:
                        differences.append(float(match.group(1)))
            
            if differences:
                # Une variance faible = bonne coh√©rence temporelle
                return 1.0 - min(np.var(differences) / 1000.0, 1.0)
            else:
                return 0.5
                
        except subprocess.CalledProcessError:
            return 0.5
    def _score_nnedi(self, a: VideoAnalysis) -> float:
        """Score pour nnedi (neural network, haute qualit√©)"""
        score = 0.55  # Base √©lev√©e (qualit√© sup√©rieure)
        
        # Excellent pour haute qualit√© et d√©tails fins
        if a.complexity > 0.2:
            score += 0.3
        
        # Tr√®s bon pour mouvement faible √† moyen
        if a.avg_motion < self.THRESHOLDS['high_motion']:
            score += 0.2
        
        # Bonus pour coh√©rence temporelle √©lev√©e
        if a.temporal_consistency > 0.6:
            score += 0.15
        
        # P√©nalit√© si mouvement tr√®s rapide (co√ªteux en calcul)
        if a.avg_motion > 0.25:
            score -= 0.25
        
        # Bonus si contenu tr√®s d√©taill√©
        if a.complexity > self.THRESHOLDS['high_complexity']:
            score += 0.2
        
        return max(0.0, min(1.0, score))
    
    def recommend_filter(self) -> FilterRecommendation:
        """
        Recommande le meilleur filtre bas√© sur l'analyse
        
        Logique de d√©cision:
        - YADIF: Contenu simple, mouvement faible √† moyen, bon compromis
        - BWDIF: Contenu complexe, mouvement moyen, meilleure qualit√©
        - ESTDIF: Mouvement √©lev√©, sport, action
        - W3FDIF: Contenu film, coh√©rence temporelle √©lev√©e
        - NNEDI: Haute qualit√©, d√©tails fins, mouvement faible √† moyen
        """
        if self.analysis is None:
            self.analyze_video()
        
        a = self.analysis
        t = self.THRESHOLDS
        
        print(f"\nüìä R√©sultats de l'analyse:")
        print(f"  Mouvement moyen: {a.avg_motion:.3f}")
        print(f"  Mouvement max: {a.max_motion:.3f}")
        print(f"  Variance mouvement: {a.motion_variance:.3f}")
        print(f"  Changements de sc√®ne: {a.scene_changes}")
        print(f"  Complexit√© spatiale: {a.complexity:.3f}")
        print(f"  Ratio entrelacement: {a.interlaced_frames:.3f}")
        print(f"  Contenu film: {a.has_film_content}")
        print(f"  Coh√©rence temporelle: {a.temporal_consistency:.3f}")
        
        # Calcul du score pour chaque filtre
        scores = {
            DeinterlaceFilter.YADIF: self._score_yadif(a),
            DeinterlaceFilter.BWDIF: self._score_bwdif(a),
            DeinterlaceFilter.ESTDIF: self._score_estdif(a),
            DeinterlaceFilter.W3FDIF: self._score_w3fdif(a),
            DeinterlaceFilter.NNEDI: self._score_nnedi(a)
        }
        
        # S√©lectionner le meilleur
        best_filter = max(scores.items(), key=lambda x: x[1])
        
        # Trouver l'alternative
        scores_sorted = sorted(scores.items(), key=lambda x: x[1], reverse=True)
        alternative = scores_sorted[1][0] if len(scores_sorted) > 1 else None
        
        # D√©terminer le mode (0=25fps, 1=50fps)
        mode = 1 if a.avg_motion > t['low_motion'] else 0
        
        # G√©n√©rer la raison
        reason = self._generate_reason(best_filter[0], a, t)
        
        return FilterRecommendation(
            filter=best_filter[0],
            mode=mode,
            confidence=best_filter[1],
            reason=reason,
            alternative=alternative
        )
    
    def _score_yadif(self, a: VideoAnalysis) -> float:
        """Score pour yadif (filtre standard, polyvalent)"""
        score = 0.5  # Base
        
        # Bon pour mouvement faible √† moyen
        if a.avg_motion < self.THRESHOLDS['high_motion']:
            score += 0.2
        
        # Bon pour complexit√© faible √† moyenne
        if a.complexity < self.THRESHOLDS['high_complexity']:
            score += 0.15
        
        # P√©nalit√© si mouvement tr√®s √©lev√©
        if a.avg_motion > self.THRESHOLDS['high_motion'] * 1.5:
            score -= 0.2
        
        # Bonus si c'est clairement entrelac√©
        if a.interlaced_frames > 0.7:
            score += 0.15
        
        return max(0.0, min(1.0, score))
    
    def _score_bwdif(self, a: VideoAnalysis) -> float:
        """Score pour bwdif (meilleure qualit√© que yadif)"""
        score = 0.6  # Base plus √©lev√©e
        
        # Excellent pour complexit√© moyenne √† √©lev√©e
        if a.complexity > 0.15:
            score += 0.25
        
        # Bon pour mouvement moyen
        if 0.05 < a.avg_motion < 0.2:
            score += 0.2
        
        # Bonus si beaucoup de d√©tails
        if a.complexity > self.THRESHOLDS['high_complexity']:
            score += 0.15
        
        # L√©g√®re p√©nalit√© si mouvement tr√®s rapide
        if a.avg_motion > 0.25:
            score -= 0.1
        
        return max(0.0, min(1.0, score))
    
    def _score_estdif(self, a: VideoAnalysis) -> float:
        """Score pour estdif (optimis√© mouvement rapide)"""
        score = 0.4  # Base
        
        # Excellent pour mouvement √©lev√©
        if a.avg_motion > self.THRESHOLDS['high_motion']:
            score += 0.4
        
        # Bonus pour mouvement tr√®s rapide
        if a.avg_motion > 0.2:
            score += 0.2
        
        # Bon pour beaucoup de changements de sc√®ne
        scene_rate = a.scene_changes / (self.sample_duration * 25)
        if scene_rate > self.THRESHOLDS['scene_change_rate']:
            score += 0.15
        
        # P√©nalit√© si mouvement faible
        if a.avg_motion < self.THRESHOLDS['low_motion']:
            score -= 0.3
        
        return max(0.0, min(1.0, score))
    
    def _score_w3fdif(self, a: VideoAnalysis) -> float:
        """Score pour w3fdif (bon pour contenu film)"""
        score = 0.45  # Base
        
        # Excellent pour contenu film
        if a.has_film_content:
            score += 0.4
        
        # Bon pour coh√©rence temporelle √©lev√©e
        if a.temporal_consistency > 0.7:
            score += 0.25
        
        # Bonus si mouvement faible (typique du film)
        if a.avg_motion < self.THRESHOLDS['low_motion']:
            score += 0.15
        
        # P√©nalit√© si variance de mouvement √©lev√©e
        if a.motion_variance > 0.1:
            score -= 0.2
        
        return max(0.0, min(1.0, score))
    
    def _generate_reason(self, filter: DeinterlaceFilter, 
                        a: VideoAnalysis, t: Dict) -> str:
        """G√©n√®re une explication de la recommandation"""
        reasons = []
        
        if filter == DeinterlaceFilter.YADIF:
            reasons.append("Filtre polyvalent adapt√© au contenu")
            if a.avg_motion < t['high_motion']:
                reasons.append("mouvement faible √† moyen d√©tect√©")
            if a.complexity < t['high_complexity']:
                reasons.append("complexit√© spatiale mod√©r√©e")
        
        elif filter == DeinterlaceFilter.BWDIF:
            reasons.append("Meilleure qualit√© que yadif recommand√©e")
            if a.complexity > 0.15:
                reasons.append("complexit√© spatiale √©lev√©e d√©tect√©e")
            reasons.append("pr√©servation optimale des d√©tails")
        
        elif filter == DeinterlaceFilter.ESTDIF:
            reasons.append("Optimis√© pour mouvement rapide")
            if a.avg_motion > t['high_motion']:
                reasons.append(f"mouvement √©lev√© d√©tect√© ({a.avg_motion:.3f})")
            if a.scene_changes > t['scene_change_rate'] * self.sample_duration * 25:
                reasons.append("nombreux changements de sc√®ne")
        
        elif filter == DeinterlaceFilter.W3FDIF:
            reasons.append("Optimis√© pour contenu film")
            if a.has_film_content:
                reasons.append("contenu t√©l√©cin√© d√©tect√©")
            if a.temporal_consistency > 0.7:
                reasons.append("excellente coh√©rence temporelle")
                
        elif filter == DeinterlaceFilter.NNEDI:
            reasons.append("Qualit√© maximale avec r√©seau neuronal")
            if a.complexity > 0.2:
                reasons.append("d√©tails fins et complexit√© √©lev√©e")
            if a.avg_motion < t['high_motion']:
                reasons.append("mouvement adapt√© pour traitement neuronal")
            reasons.append("pr√©servation exceptionnelle des bords")
            
        return ", ".join(reasons)
    
    def generate_ffmpeg_command(self, output_path: str, 
                               codec: str = 'prores_ks',
                               profile: int = 3) -> str:
        """
        G√©n√®re la commande FFmpeg compl√®te avec le filtre recommand√©
        """
        if self.analysis is None:
            self.analyze_video()
        
        rec = self.recommend_filter()
        
        # Construire le filtre
        if rec.filter == DeinterlaceFilter.YADIF:
            vf = f"yadif={rec.mode}"
        elif rec.filter == DeinterlaceFilter.BWDIF:
            vf = f"bwdif={rec.mode}"
        elif rec.filter == DeinterlaceFilter.ESTDIF:
            vf = f"estdif=mode={rec.mode}"
        elif rec.filter == DeinterlaceFilter.NNEDI:
            # NNEDI avec param√®tres optimaux
            #vf = f"nnedi=deint={'interlaced' if rec.mode == 1 else 'all'}"
            vf = f"nnedi=weights=nnedi3_weights.bin"
        else:  # W3FDIF
            vf = "w3fdif"
        
        
        # Ajouter le format de pixel pour ProRes
        if codec == 'prores_ks':
            vf += ",format=yuv422p10le"
        
        cmd = (
            f"ffmpeg -i {self.video_path} "
            f"-vf \"{vf}\" "
            f"-c:v {codec} -profile:v {profile} "
            f"-c:a copy "
            f"{output_path}"
        )
        
        return cmd


def main():
    """Exemple d'utilisation"""
    import sys
    
    if len(sys.argv) < 2:
        print("Usage: python deinterlace_selector.py <video_file> [output_file]")
        sys.exit(1)
    
    video_path = sys.argv[1]
    output_path = sys.argv[2] if len(sys.argv) > 2 else "output.mov"
    
    # Cr√©er le s√©lecteur
    selector = DeinterlaceSelector(video_path, sample_duration=30)
    
    # Analyser
    print("=" * 60)
    analysis = selector.analyze_video()
    print("=" * 60)
    
    # Obtenir la recommandation
    recommendation = selector.recommend_filter()
    
    print(f"\n‚úÖ Recommandation:")
    print(f"  Filtre: {recommendation.filter.value}")
    print(f"  Mode: {recommendation.mode} ({'50fps' if recommendation.mode == 1 else '25fps'})")
    print(f"  Confiance: {recommendation.confidence:.1%}")
    print(f"  Raison: {recommendation.reason}")
    if recommendation.alternative:
        print(f"  Alternative: {recommendation.alternative.value}")
    
    # G√©n√©rer la commande
    print(f"\nüé¨ Commande FFmpeg:")
    cmd = selector.generate_ffmpeg_command(output_path)
    print(f"  {cmd}")
    
    print(f"\nüí° Pour ex√©cuter:")
    print(f"  {cmd}")


if __name__ == '__main__':
    main()
